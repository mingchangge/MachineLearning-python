import os
import shutil
import random
import pandas as pd
from tqdm import tqdm

# ===================================================================
# --- 1. é…ç½® (æ‚¨å”¯ä¸€éœ€è¦ä¿®æ”¹çš„åœ°æ–¹) ---
# ===================================================================

# æ—§çš„ã€åºå¤§çš„åˆæˆæ•°æ®é›†è·¯å¾„
OLD_SYNTHETIC_DIR = "../ocr_dataset_hybrid"

# æ–°çš„ã€é«˜è´¨é‡çš„â€œé»„é‡‘â€çœŸå®æ•°æ®é›†è·¯å¾„
NEW_FINETUNE_DIR = "../stratified_dataset_split"

# è¾“å‡ºï¼šå°†è¦åˆ›å»ºçš„æœ€ç»ˆâ€œä¸‰æ˜æ²»â€æ··åˆæ•°æ®é›†çš„æ–‡ä»¶å¤¹åç§°
OUTPUT_DIR = "../stratified_mixed_dataset"

# ã€å…³é”®ã€‘æ‚¨å¸Œæœ›ä»æ—§æ•°æ®é›†ä¸­éšæœºæŠ½å–çš„æ ·æœ¬æ•°é‡
NUM_OLD_SAMPLES_TO_USE = 2750 # æ¨èä½¿ç”¨ 1:5 çš„æ¯”ä¾‹

# ===================================================================

def merge_datasets():
    """
    ä¸»å‡½æ•°ï¼Œæ‰§è¡Œæ‰€æœ‰åˆå¹¶æ“ä½œã€‚
    """
    print(f"ğŸš€ å¼€å§‹åˆ›å»ºâ€œä¸‰æ˜æ²»â€æ··åˆæ•°æ®é›† '{OUTPUT_DIR}'...")

    # --- 1. åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„ ---
    train_dir_out = os.path.join(OUTPUT_DIR, "train")
    val_dir_out = os.path.join(OUTPUT_DIR, "val")
    train_images_out = os.path.join(train_dir_out, "images")
    val_images_out = os.path.join(val_dir_out, "images")
    
    os.makedirs(train_images_out, exist_ok=True)
    os.makedirs(val_images_out, exist_ok=True)

    # --- 2. åŠ è½½æ‰€æœ‰æ ‡ç­¾ä¿¡æ¯åˆ°Pandas DataFrameä¸­ ---
    print("ğŸ“Š æ­£åœ¨åŠ è½½æ ‡ç­¾æ–‡ä»¶...")
    old_labels_path = os.path.join(OLD_SYNTHETIC_DIR, "labels.txt")
    new_train_labels_path = os.path.join(NEW_FINETUNE_DIR, "train", "labels.txt")
    new_val_labels_path = os.path.join(NEW_FINETUNE_DIR, "val", "labels.txt")

    try:
        df_old = pd.read_csv(old_labels_path, sep='\t', header=None, names=['filepath', 'transcription'])
        df_new_train = pd.read_csv(new_train_labels_path, sep='\t', header=None, names=['filepath', 'transcription'])
        df_new_val = pd.read_csv(new_val_labels_path, sep='\t', header=None, names=['filepath', 'transcription'])
    except FileNotFoundError as e:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {e.filename}ã€‚è¯·æ£€æŸ¥æ‚¨çš„ç›®å½•é…ç½®ã€‚")
        return

    # --- 3. ã€æ ¸å¿ƒã€‘å¤„ç†è®­ç»ƒé›† ---
    print(f"\nâš™ï¸ æ­£åœ¨å¤„ç†è®­ç»ƒé›†...")
    
    # éšæœºæŠ½å–æŒ‡å®šæ•°é‡çš„æ—§æ•°æ®
    if len(df_old) < NUM_OLD_SAMPLES_TO_USE:
        print(f"âš ï¸ è­¦å‘Šï¼šè¯·æ±‚çš„æ—§æ ·æœ¬æ•°é‡({NUM_OLD_SAMPLES_TO_USE})å¤§äºå®é™…æ•°é‡({len(df_old)})ã€‚å°†ä½¿ç”¨æ‰€æœ‰æ—§æ ·æœ¬ã€‚")
        df_old_sample = df_old
    else:
        df_old_sample = df_old.sample(n=NUM_OLD_SAMPLES_TO_USE, random_state=42) # random_stateç¡®ä¿æ¯æ¬¡æŠ½å–ç»“æœéƒ½ä¸€æ ·
    
    print(f"  - ä»æ—§æ•°æ®é›†ä¸­éšæœºæŠ½å– {len(df_old_sample)} ä¸ªæ ·æœ¬ã€‚")
    print(f"  - ä»æ–°æ•°æ®é›†ä¸­åŠ è½½ {len(df_new_train)} ä¸ªæ ·æœ¬ã€‚")

    # åˆå¹¶æ–°æ—§è®­ç»ƒé›†çš„æ ‡ç­¾ä¿¡æ¯
    df_final_train = pd.concat([df_old_sample, df_new_train], ignore_index=True)
    print(f"  - æœ€ç»ˆè®­ç»ƒé›†æ€»è®¡: {len(df_final_train)} ä¸ªæ ·æœ¬ã€‚")
    
    # å°†åˆå¹¶åçš„è®­ç»ƒé›†æ ‡ç­¾å†™å…¥æ–°çš„labels.txt
    final_train_labels_path = os.path.join(train_dir_out, "labels.txt")
    df_final_train.to_csv(final_train_labels_path, sep='\t', header=False, index=False)

    # å¤åˆ¶è®­ç»ƒé›†å›¾ç‰‡
    print("  - æ­£åœ¨å¤åˆ¶è®­ç»ƒé›†å›¾ç‰‡...")
    # å¤åˆ¶æ—§å›¾ç‰‡
    for _, row in tqdm(df_old_sample.iterrows(), total=len(df_old_sample), desc="å¤åˆ¶æ—§å›¾ç‰‡"):
        src = os.path.join(OLD_SYNTHETIC_DIR, row['filepath'])
        dst = os.path.join(train_images_out, os.path.basename(row['filepath']))
        if os.path.exists(src): shutil.copyfile(src, dst)
    # å¤åˆ¶æ–°å›¾ç‰‡
    for _, row in tqdm(df_new_train.iterrows(), total=len(df_new_train), desc="å¤åˆ¶æ–°å›¾ç‰‡"):
        src = os.path.join(NEW_FINETUNE_DIR, "train", row['filepath'])
        dst = os.path.join(train_images_out, os.path.basename(row['filepath']))
        if os.path.exists(src): shutil.copyfile(src, dst)

    # --- 4. ã€æ ¸å¿ƒã€‘å¤„ç†éªŒè¯é›† (åªä½¿ç”¨æ–°çš„â€œé»„é‡‘â€éªŒè¯é›†) ---
    print(f"\nâš™ï¸ æ­£åœ¨å¤„ç†éªŒè¯é›†...")
    print(f"  - åŠ è½½ {len(df_new_val)} ä¸ªâ€œé»„é‡‘â€éªŒè¯æ ·æœ¬ã€‚")
    
    # å†™å…¥éªŒè¯é›†æ ‡ç­¾
    final_val_labels_path = os.path.join(val_dir_out, "labels.txt")
    df_new_val.to_csv(final_val_labels_path, sep='\t', header=False, index=False)

    # å¤åˆ¶éªŒè¯é›†å›¾ç‰‡
    print("  - æ­£åœ¨å¤åˆ¶éªŒè¯é›†å›¾ç‰‡...")
    for _, row in tqdm(df_new_val.iterrows(), total=len(df_new_val), desc="å¤åˆ¶éªŒè¯å›¾ç‰‡"):
        src = os.path.join(NEW_FINETUNE_DIR, "val", row['filepath'])
        dst = os.path.join(val_images_out, os.path.basename(row['filepath']))
        if os.path.exists(src): shutil.copyfile(src, dst)

    print(f"\nğŸ‰ğŸ‰ğŸ‰ æˆåŠŸï¼æœ€ç»ˆçš„â€œä¸‰æ˜æ²»â€æ··åˆæ•°æ®é›†å·²åœ¨ '{OUTPUT_DIR}' æ–‡ä»¶å¤¹ä¸­åˆ›å»ºã€‚")
    print("ä¸‹ä¸€æ­¥ï¼šè¯·å°†è¿™ä¸ªæ–‡ä»¶å¤¹æ‰“åŒ…æˆ.zipï¼Œä¸Šä¼ åˆ°Colabè¿›è¡Œæœ€ç»ˆçš„å¾®è°ƒè®­ç»ƒã€‚")


if __name__ == "__main__":
    merge_datasets()